{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST IT Cloud - Data and Analytics Test LV.4\n",
    "\n",
    "Esse teste deve avaliar alguns conceitos de big data e a qualidade técnica na manipulacão de dados, otimização de performance, trabalho com arquivos grandes e tratamento de qualidade.\n",
    "\n",
    "## Passo a passo\n",
    "\n",
    "- *Parte teórica:* responda as questões abaixo preenchendo as células em branco.\n",
    "- *Parte prática:* disponibilizamos aqui 2 cases para, leia os enunciados dos problemas, desenvolver os programas, utilizando a **stack definida durante o processo seletivo**, para entregar os dados de acordo com os requisitos descritos abaixo.\n",
    "\n",
    "\n",
    "\n",
    "**Faz parte dos critérios de avaliacão a pontualidade da entrega. Implemente até onde for possível dentro do prazo acordado.**\n",
    "\n",
    "**Os dados de pessoas foram gerados de forma aleatória, utilizando a biblioteca FakerJS, FakerJS-BR e Faker**\n",
    "\n",
    "LEMBRE-SE: A entrega deve conter TODOS os passos para o avaliador executar o programa (keep it simple).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 1** - Descreva de forma detalhada quais são as etapas na construção de um pipeline de dados, sem considerar ferramentas específicas, imagine que é seu primeiro contato com o cliente e você precisa entender a demanda dele e explicar quais são os passos que você terá que implementar para entregar a demanda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Avaliar o Problema de Negocio 2- Avaliar as possiveis soluções e abordagens para resolver o problema  3- Escolher um caminho a seguir entre as abordagens 5- Desenhar a Solução 4- Definir quais Ferramentas serão utilizadas 5- Desenvolver um prototipo inicial 6 - Fazer as Validações internas e testes com o Usuario 7- Fazer Deploy em Produçao, é um processo que tem um inicio , meio e fim , ou do ponto de vista dos dados tem uma entrada , processamento e saida ou seja é a montagem de um fluxo operacional a ser seguido que tem um inicio e um fim em termos operacionais , e que pode ser aplicado a qualquer coisa , desde de a um gerenciamento de produção de uma fabrica que fabrica determinado produto , ou a uma Fabrica de Sottware que desenvolve aplicativos ou mesmo a uma arquitetura de fluxo operacional de dados, ou seja se trata de gerenciamento organizado de fluxo operacional de trabalho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 2** - Defina com suas palavras um processamento em streaming e processamento em batch. Qual sua experiência com cada uma delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento em Streaming é o processamento em tempo real ou seja no momento da produção da informação (como por exemplo a coleta de uma informação de venda online que acabou de acontecer), processamento em batch é um processamento através de lotes ou seja é enviado lotes de dados com tamanhos pre-definidos para processamento em intervalos de tempo pre definidos e pode ser muito tempo depois do fato ter ocorrido ou pode ser proximo ao tempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 3** - Quais são as camadas de um Data Lake?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingestão , Armazenamento em Cache e Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 4** - Quais as diferenças de um Data Lake e um DW?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente o Data Lake suporta dados não estruturados e o Data Warehouse não suporta , mas ambos suportam dados estruturados e agregados por segmentos e tambem umm Data Lake por ser projetado para Big Data suporta armazenamento e processamento distribuido com volumes de dados gigantescos e alta integridade das informações ou seja atende ao requisito de grandes volumes de dados com alta integridade e tambem ao requisito de processamento de dados em alta velocidade, pois trabalha com armazenamento e processamento distribuido , operando através de um cluster de computadores como se fosse uma unica maquina , coisa que um DW não comporta pois não foi projetado para isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 5** - O que é arquitetura Lambda e Kappa? Descreva com suas palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura Lambda Foi desenvlvida para contornar uma limitação do MapReduce que ao processar grandes volumes de dados demorava muito para dar um retorno do resultado. Isso foi resolvido pelo menos parcialmente ,através da arquiteura Kappa que dá dois caminhos para o resultado dos dados , o caminho quente que é mais rapido mas menos preciso e em uma janela pequena de tempo e o caminho frio que é mais lento e mais demorada e em uma janela de tempo maior mas é mais preciso em relação as informações, este é processado em  Batch ,  tudo é unificado na camada de serviço que possui as informações completas unificadas entre os processamento em streeaming de dados e o processamento em batch , os dados dos eventos são imutaveis.Dessa forma acaba atendendo a necessidade de ver mais rapidamente os dados. A Arquitetura Kappa foi desenvolvida para suprir uma deficiencia da arquitetura Lambda pois havia a necessidade de dois codigos diferentes para tratar a camada em batch e a camada em streming , ja a Arquitetura Kappa pensa em termos de unificação dos dados na origem e para isso usa o Log para fazer essa unificação onde não importa de onde venha o dado , se de streaming de dados , de um csv , xml de um banco de dados , todas essas fontes de dados são tratados como eventos no arquivo de log e é um log imutavel todo o dado que entra entra como um simbolo de + e os updates e reduções de dados entram com um simbolo de - , e assim o seu processamento se torna muito mais rapido, e dessa forma tudo é processado em tempo real e armazenado em um repositório de Longo Termo e possui uma camada de serviço que serve para oferecer os dados para as ferramentas de visualização ou de extração de informações que foram processadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 6** - O que é Data Quality para você e como você implementa isso nos seus processos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É um processo de que visa validar os dados afim de manter a qualidade dos mesmos . Existe varias formas de fazer isso , como processos que validam os nomes das colunas, os tipos de dados e que comparam dados de periodos diferentes para detectar anomalizas ou falhas na produção da informação na origem dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 7** - Em uma escala de 0 a 10, qual seria seu nível de experiência com PySpark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6, utilizei no curso de Python com Spark que fiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 8** - Em uma escala de 0 a 10, qual seria seu nível de experiência com SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8 , já trabalho com a linguagem SQL e banco SQL a muito tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 9** - Descreva suas expeciências com banco de dados SQL e NoSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja trabalhei com o Banco SQL e atualmente Trabalho com Impala banco NoSQL usando a ferramenta Hue para rodar as consultas,tendo tambem o Hive como opção adicional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 10** - Tem experiência com versionamento de código? Com quais ferramentas já trabalhou? Descreva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Só conheço GitHub , utilizamos na empresa que trabalho , mas depende muito do projeto , tem projeto que usamos mais , outros usamos menos e outros não usamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 11** - Tem experiência em desenvolvimento em cloud? Se sim, especifique a(s) plataforma(s) que já trabalhou e suas principais implementações e conhecimentos em cada serviço."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não tenho , a unica ferramenta que conheço que trabalha com este Viés é o Azure Machine Learning que aprendi ela no curso que fiz de Cientista de Dados na DSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 12** - Tem experiência com metodologia ágil? Qual?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim , A maioria dos projetos que trabalhei e que estou trabalhando na Cargill utiliza a metodologia Scrum , então temos o Scrum Master que conduz a reunião em conjunto com os lideres do projeto normalmente alguem de negócio e alguem da area de TI. São realizadas reuniões diarias denominadas Dailys e as Plenys a cada 15 dias  e mais uma reunião Geral no Final da Sprint e tambem pode ser marcada uma reunião após o termino da sprint de retrospectiva para analise de pontos de dificuldades e o que pode ser melhorado para a proxima Sprint, cada Sprint são atividades de trabalhos vinculado a um prazo , são determinada metas de trabalhos e delegado as atividades aos responsaveis que terão como meta concluir as atividades até o final da Sprint, o prazo da Sprint pode varias em relação ao tempo , normalmente 15 ou 30 dias, é o que eu conheço. Mas sei que a Metodologia Scrum é bem maleavel então esta estrutura pode variar um pouco de empresa para empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTE PRÁTICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema 1**: Você está recebendo o arquivo 'dados_cadastrais_fake.csv' que contem dados cadastrais de clientes, mas para que análises ou relatórios sejam feitos é necessário limpar e normalizar os dados. Além disso, existe uma coluna com o número de cpf e outra com cnpj, você precisará padronizar deixando apenas dígitos em formato string (sem caracteres especiais), implementar uma forma de verificar se tais documentos são válidos sendo que a informação deve se adicionada ao dataframe em outras duas novas colunas.\n",
    "\n",
    "Após a normalização, gere reports que respondam as seguintes perguntas:\n",
    "- Quantos clientes temos nessa base?\n",
    "- Qual a média de idade dos clientes?\n",
    "- Quantos clientes nessa base pertencem a cada estado?\n",
    "- Quantos CPFs válidos e inválidos foram encontrados?\n",
    "- Quantos CNPJs válidos e inválidos foram encontrados?\n",
    "\n",
    "Ao final gere um arquivo no formato csv e um outro arquivo no formato parquet chamado (problema1_normalizado), eles serão destinados para pessoas distintas.\n",
    "\n",
    "*EXTRA:* executar as mesmas validações no *1E8.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando e Importando Bibliotecas e Modulos\n",
    "# !pip install --user pandas -U\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "#Importa Modulo Adicional\n",
    "import validacpfcnpj\n",
    "\n",
    "#Desativa os avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria funcao secundaria \n",
    "\n",
    "def roda_validacao_cpf_cnpj(a):\n",
    "    \n",
    "    cpf_cnpj = validacpfcnpj.ValidaCpfCnpj(str(a))\n",
    "\n",
    "    \n",
    "    return cpf_cnpj.valida()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testa Função com CPF - True\n",
    "roda_validacao_cpf_cnpj(97566536800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testa Função com CPF - False\n",
    "roda_validacao_cpf_cnpj(97566536801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testa Função com CNPJ - True\n",
    "roda_validacao_cpf_cnpj(\"06589184909526\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testa Função com CNPJ - false\n",
    "roda_validacao_cpf_cnpj(\"06589184909521\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "      <th>idade</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>cpf</th>\n",
       "      <th>cnpj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dennis Daniels</td>\n",
       "      <td>31</td>\n",
       "      <td>ACRELÂNDIA</td>\n",
       "      <td>AC</td>\n",
       "      <td>97566536800</td>\n",
       "      <td>06589184909526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leah Becker</td>\n",
       "      <td>42</td>\n",
       "      <td>ÁGUA BRANCA</td>\n",
       "      <td>AL</td>\n",
       "      <td>425.263.807-07</td>\n",
       "      <td>25.673.336/2350-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sally Ford</td>\n",
       "      <td>18</td>\n",
       "      <td>ALVARÃES</td>\n",
       "      <td>AM</td>\n",
       "      <td>34647754103</td>\n",
       "      <td>26543101702989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colleen Duncan</td>\n",
       "      <td>21</td>\n",
       "      <td>SERRA DO NAVIO</td>\n",
       "      <td>AP</td>\n",
       "      <td>252.531.560-03</td>\n",
       "      <td>19.062.080/5100-98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Stephenson</td>\n",
       "      <td>73</td>\n",
       "      <td>ABAÍRA</td>\n",
       "      <td>BA</td>\n",
       "      <td>49668886542</td>\n",
       "      <td>97794530015384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Rebekah Mitchell PhD</td>\n",
       "      <td>55</td>\n",
       "      <td>ABAIARA</td>\n",
       "      <td>CE</td>\n",
       "      <td>744.822.622-34</td>\n",
       "      <td>16.740.076/9329-75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Lisa Parrish Jr.</td>\n",
       "      <td>73</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>DF</td>\n",
       "      <td>10683395190</td>\n",
       "      <td>32246978843482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Michael Young MD</td>\n",
       "      <td>87</td>\n",
       "      <td>AFONSO CLÁUDIO</td>\n",
       "      <td>ES</td>\n",
       "      <td>538.223.638-04</td>\n",
       "      <td>86.601.303/7580-88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Kevin Watson DDS</td>\n",
       "      <td>82</td>\n",
       "      <td>ABADIA DE GOIÁS</td>\n",
       "      <td>GO</td>\n",
       "      <td>11632512408</td>\n",
       "      <td>08651414023648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Mr. Joseph Wilson MD</td>\n",
       "      <td>50</td>\n",
       "      <td>AÇAILÂNDIA</td>\n",
       "      <td>MA</td>\n",
       "      <td>192.134.492-08</td>\n",
       "      <td>08.908.871/5161-91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nomes  idade           cidade estado             cpf  \\\n",
       "0           Dennis Daniels     31       ACRELÂNDIA     AC     97566536800   \n",
       "1              Leah Becker     42      ÁGUA BRANCA     AL  425.263.807-07   \n",
       "2               Sally Ford     18         ALVARÃES     AM     34647754103   \n",
       "3           Colleen Duncan     21   SERRA DO NAVIO     AP  252.531.560-03   \n",
       "4          Jeff Stephenson     73           ABAÍRA     BA     49668886542   \n",
       "...                    ...    ...              ...    ...             ...   \n",
       "9995  Rebekah Mitchell PhD     55          ABAIARA     CE  744.822.622-34   \n",
       "9996      Lisa Parrish Jr.     73         Brasília     DF     10683395190   \n",
       "9997      Michael Young MD     87   AFONSO CLÁUDIO     ES  538.223.638-04   \n",
       "9998      Kevin Watson DDS     82  ABADIA DE GOIÁS     GO     11632512408   \n",
       "9999  Mr. Joseph Wilson MD     50       AÇAILÂNDIA     MA  192.134.492-08   \n",
       "\n",
       "                    cnpj  \n",
       "0         06589184909526  \n",
       "1     25.673.336/2350-20  \n",
       "2         26543101702989  \n",
       "3     19.062.080/5100-98  \n",
       "4         97794530015384  \n",
       "...                  ...  \n",
       "9995  16.740.076/9329-75  \n",
       "9996      32246978843482  \n",
       "9997  86.601.303/7580-88  \n",
       "9998      08651414023648  \n",
       "9999  08.908.871/5161-91  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando o método read_csv\n",
    "df =pd.read_table('dados_cadastrais_fake.csv', sep = ';',encoding=\"utf8\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantos clientes temos nessa base? R: 33 clientes distintos\n",
    "max(df.nomes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.7831"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual a média de idade dos clientes? R: 53 anos \n",
    "df.idade.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantos clientes nessa base pertencem a cada estado? \n",
    "   R: Segue a lista abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estado</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PI</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RJ</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RN</th>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RR</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nomes\n",
       "estado       \n",
       "AC        365\n",
       "AL        362\n",
       "AM        360\n",
       "AP        365\n",
       "BA        364\n",
       "CE        364\n",
       "DF        361\n",
       "ES        359\n",
       "GO        365\n",
       "MA        364\n",
       "MG        360\n",
       "MS        361\n",
       "MT        365\n",
       "PA        361\n",
       "PB        366\n",
       "PE        362\n",
       "PI        363\n",
       "PR        362\n",
       "RJ        362\n",
       "RN        359\n",
       "RO        363\n",
       "RR        362\n",
       "RS        360\n",
       "SC        361\n",
       "SE        363\n",
       "SP        363\n",
       "TO        363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['estado'].replace({' ':''},inplace=True, regex=True)\n",
    "df.replace({'MINASGERAI':'MG','MINASGERAIs':'MG','distritofederal':'DF','riodejaneiro':'RJ','saopaulo':'SP',\n",
    "            'sãopaulo':'SP'},inplace=True)\n",
    "df[['estado','nomes']].groupby(['estado']).nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantos CPFs válidos e inválidos foram encontrados?\n",
    "   R: Foram encontrado 10 mil cpfs validos ou seja todos os cpfs da base csv fornecida são validos.Não foram encontrados nenhum cpf invalido.\n",
    " \n",
    "    --> Segue detalhes do código abaixo\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "      <th>idade</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>cpf</th>\n",
       "      <th>cnpj</th>\n",
       "      <th>valida_cpf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dennis Daniels</td>\n",
       "      <td>31</td>\n",
       "      <td>ACRELÂNDIA</td>\n",
       "      <td>AC</td>\n",
       "      <td>97566536800</td>\n",
       "      <td>06589184909526</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leah Becker</td>\n",
       "      <td>42</td>\n",
       "      <td>ÁGUA BRANCA</td>\n",
       "      <td>AL</td>\n",
       "      <td>42526380707</td>\n",
       "      <td>25.673.336/2350-20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sally Ford</td>\n",
       "      <td>18</td>\n",
       "      <td>ALVARÃES</td>\n",
       "      <td>AM</td>\n",
       "      <td>34647754103</td>\n",
       "      <td>26543101702989</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colleen Duncan</td>\n",
       "      <td>21</td>\n",
       "      <td>SERRA DO NAVIO</td>\n",
       "      <td>AP</td>\n",
       "      <td>25253156003</td>\n",
       "      <td>19.062.080/5100-98</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Stephenson</td>\n",
       "      <td>73</td>\n",
       "      <td>ABAÍRA</td>\n",
       "      <td>BA</td>\n",
       "      <td>49668886542</td>\n",
       "      <td>97794530015384</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Rebekah Mitchell PhD</td>\n",
       "      <td>55</td>\n",
       "      <td>ABAIARA</td>\n",
       "      <td>CE</td>\n",
       "      <td>74482262234</td>\n",
       "      <td>16.740.076/9329-75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Lisa Parrish Jr.</td>\n",
       "      <td>73</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>DF</td>\n",
       "      <td>10683395190</td>\n",
       "      <td>32246978843482</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Michael Young MD</td>\n",
       "      <td>87</td>\n",
       "      <td>AFONSO CLÁUDIO</td>\n",
       "      <td>ES</td>\n",
       "      <td>53822363804</td>\n",
       "      <td>86.601.303/7580-88</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Kevin Watson DDS</td>\n",
       "      <td>82</td>\n",
       "      <td>ABADIA DE GOIÁS</td>\n",
       "      <td>GO</td>\n",
       "      <td>11632512408</td>\n",
       "      <td>08651414023648</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Mr. Joseph Wilson MD</td>\n",
       "      <td>50</td>\n",
       "      <td>AÇAILÂNDIA</td>\n",
       "      <td>MA</td>\n",
       "      <td>19213449208</td>\n",
       "      <td>08.908.871/5161-91</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nomes  idade           cidade estado          cpf  \\\n",
       "0           Dennis Daniels     31       ACRELÂNDIA     AC  97566536800   \n",
       "1              Leah Becker     42      ÁGUA BRANCA     AL  42526380707   \n",
       "2               Sally Ford     18         ALVARÃES     AM  34647754103   \n",
       "3           Colleen Duncan     21   SERRA DO NAVIO     AP  25253156003   \n",
       "4          Jeff Stephenson     73           ABAÍRA     BA  49668886542   \n",
       "...                    ...    ...              ...    ...          ...   \n",
       "9995  Rebekah Mitchell PhD     55          ABAIARA     CE  74482262234   \n",
       "9996      Lisa Parrish Jr.     73         Brasília     DF  10683395190   \n",
       "9997      Michael Young MD     87   AFONSO CLÁUDIO     ES  53822363804   \n",
       "9998      Kevin Watson DDS     82  ABADIA DE GOIÁS     GO  11632512408   \n",
       "9999  Mr. Joseph Wilson MD     50       AÇAILÂNDIA     MA  19213449208   \n",
       "\n",
       "                    cnpj  valida_cpf  \n",
       "0         06589184909526        True  \n",
       "1     25.673.336/2350-20        True  \n",
       "2         26543101702989        True  \n",
       "3     19.062.080/5100-98        True  \n",
       "4         97794530015384        True  \n",
       "...                  ...         ...  \n",
       "9995  16.740.076/9329-75        True  \n",
       "9996      32246978843482        True  \n",
       "9997  86.601.303/7580-88        True  \n",
       "9998      08651414023648        True  \n",
       "9999  08.908.871/5161-91        True  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[['cpf_limpo']]= df[['cpf']].replace({'.':'','-':'','/':''},inplace=True, regex=True)\n",
    "\n",
    "df['cpf'] = df['cpf'].str.replace('.', '')\n",
    "df['cpf'] = df['cpf'].str.replace('-', '')\n",
    "\n",
    "\n",
    "#df[['valida_cpf']]=df[['cpf']].apply(roda_validacao_cpf_cnpj)\n",
    "df['valida_cpf']=df['cpf'].apply(roda_validacao_cpf_cnpj)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valida_cpf</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cpf\n",
       "valida_cpf       \n",
       "True        10000"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todos os 10 mil registros são True ou seja todos os Cnpjs são validos\n",
    "df[['cpf','valida_cpf']].groupby(['valida_cpf']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os 10 mil registros possuem no campo CPF 11 carateres validos , ou seja nõo existe nenhum registro que foge ao padrão de \n",
    "# Numeros de carateres validos\n",
    "\n",
    "dfx=df[df['cpf'].str.len() == 11]\n",
    "max(dfx.valida_cpf.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantos CNPJs válidos e inválidos foram encontrados?\n",
    "    R: Todos os 10 mil registros de CNPJ  existentes no arquivo CSV analisado , são validos , não forma encontrados nenhum   cnpj invalido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "      <th>idade</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>cpf</th>\n",
       "      <th>cnpj</th>\n",
       "      <th>valida_cpf</th>\n",
       "      <th>valida_cnpj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dennis Daniels</td>\n",
       "      <td>31</td>\n",
       "      <td>ACRELÂNDIA</td>\n",
       "      <td>AC</td>\n",
       "      <td>97566536800</td>\n",
       "      <td>06589184909526</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leah Becker</td>\n",
       "      <td>42</td>\n",
       "      <td>ÁGUA BRANCA</td>\n",
       "      <td>AL</td>\n",
       "      <td>42526380707</td>\n",
       "      <td>25673336235020</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sally Ford</td>\n",
       "      <td>18</td>\n",
       "      <td>ALVARÃES</td>\n",
       "      <td>AM</td>\n",
       "      <td>34647754103</td>\n",
       "      <td>26543101702989</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colleen Duncan</td>\n",
       "      <td>21</td>\n",
       "      <td>SERRA DO NAVIO</td>\n",
       "      <td>AP</td>\n",
       "      <td>25253156003</td>\n",
       "      <td>19062080510098</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Stephenson</td>\n",
       "      <td>73</td>\n",
       "      <td>ABAÍRA</td>\n",
       "      <td>BA</td>\n",
       "      <td>49668886542</td>\n",
       "      <td>97794530015384</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Rebekah Mitchell PhD</td>\n",
       "      <td>55</td>\n",
       "      <td>ABAIARA</td>\n",
       "      <td>CE</td>\n",
       "      <td>74482262234</td>\n",
       "      <td>16740076932975</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Lisa Parrish Jr.</td>\n",
       "      <td>73</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>DF</td>\n",
       "      <td>10683395190</td>\n",
       "      <td>32246978843482</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Michael Young MD</td>\n",
       "      <td>87</td>\n",
       "      <td>AFONSO CLÁUDIO</td>\n",
       "      <td>ES</td>\n",
       "      <td>53822363804</td>\n",
       "      <td>86601303758088</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Kevin Watson DDS</td>\n",
       "      <td>82</td>\n",
       "      <td>ABADIA DE GOIÁS</td>\n",
       "      <td>GO</td>\n",
       "      <td>11632512408</td>\n",
       "      <td>08651414023648</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Mr. Joseph Wilson MD</td>\n",
       "      <td>50</td>\n",
       "      <td>AÇAILÂNDIA</td>\n",
       "      <td>MA</td>\n",
       "      <td>19213449208</td>\n",
       "      <td>08908871516191</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nomes  idade           cidade estado          cpf  \\\n",
       "0           Dennis Daniels     31       ACRELÂNDIA     AC  97566536800   \n",
       "1              Leah Becker     42      ÁGUA BRANCA     AL  42526380707   \n",
       "2               Sally Ford     18         ALVARÃES     AM  34647754103   \n",
       "3           Colleen Duncan     21   SERRA DO NAVIO     AP  25253156003   \n",
       "4          Jeff Stephenson     73           ABAÍRA     BA  49668886542   \n",
       "...                    ...    ...              ...    ...          ...   \n",
       "9995  Rebekah Mitchell PhD     55          ABAIARA     CE  74482262234   \n",
       "9996      Lisa Parrish Jr.     73         Brasília     DF  10683395190   \n",
       "9997      Michael Young MD     87   AFONSO CLÁUDIO     ES  53822363804   \n",
       "9998      Kevin Watson DDS     82  ABADIA DE GOIÁS     GO  11632512408   \n",
       "9999  Mr. Joseph Wilson MD     50       AÇAILÂNDIA     MA  19213449208   \n",
       "\n",
       "                cnpj  valida_cpf  valida_cnpj  \n",
       "0     06589184909526        True         True  \n",
       "1     25673336235020        True         True  \n",
       "2     26543101702989        True         True  \n",
       "3     19062080510098        True         True  \n",
       "4     97794530015384        True         True  \n",
       "...              ...         ...          ...  \n",
       "9995  16740076932975        True         True  \n",
       "9996  32246978843482        True         True  \n",
       "9997  86601303758088        True         True  \n",
       "9998  08651414023648        True         True  \n",
       "9999  08908871516191        True         True  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[['cpf_limpo']]= df[['cpf']].replace({'.':'','-':'','/':''},inplace=True, regex=True)\n",
    "\n",
    "df['cnpj'] = df['cnpj'].str.replace('.', '')\n",
    "df['cnpj'] = df['cnpj'].str.replace('/', '')\n",
    "df['cnpj'] = df['cnpj'].str.replace('-', '')\n",
    "\n",
    "\n",
    "#df[['valida_cpf']]=df[['cpf']].apply(roda_validacao_cpf_cnpj)\n",
    "df['valida_cnpj']=df['cnpj'].apply(roda_validacao_cpf_cnpj)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnpj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valida_cnpj</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cnpj\n",
       "valida_cnpj       \n",
       "True         10000"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['cnpj','valida_cnpj']].groupby(['valida_cnpj']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os 10 mil registros possuem no campo CNPJ 14 carateres validos , ou seja nõo existe nenhum registro que foge ao padrão de \n",
    "# Numeros de carateres validos\n",
    "dfx=df[df['cnpj'].str.len() == 14]\n",
    "max(dfx.valida_cnpj.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Gere um arquivo no formato csv chamado problema1_normalizado\n",
    "    --> Gerado Segue o código abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando Para CSV\n",
    "df.to_csv('problema1_normalizado.csv', index = False, sep=';', encoding='utf-8'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando Para Parquet\n",
    "df.to_parquet(\"./problema1_normalizado.pq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Não houve tempo habil para desenvolver as demais atividades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema 2**: Você deverá implementar um programa, para ler, tratar e particionar os dados.\n",
    "\n",
    "O arquivo fonte está disponível em `https://st-it-cloud-public.s3.amazonaws.com/people-v2_1E6.csv.gz`\n",
    "\n",
    "### Data Quality\n",
    "\n",
    "- Higienizar e homogenizar o formato da coluna `document`\n",
    "- Detectar através da coluna `document` se o registro é de uma Pessoa Física ou Pessoa Jurídica, adicionando uma coluna com essa informação\n",
    "- Higienizar e homogenizar o formato da coluna `birthDate`\n",
    "- Existem duas colunas nesse dataset que em alguns registros estão trocadas. Quais são essas colunas? \n",
    "- Corrigir os dados com as colunas trocadas\n",
    "- Além desses pontos, existem outras tratamentos para homogenizar esse dataset. Aplique todos que conseguir.\n",
    "\n",
    "### Agregação dos dados\n",
    "\n",
    "- Quais são as 5 PF que mais gastaram (`totalSpent`)? \n",
    "- Qual é o valor de gasto médio por estado (`state`)?\n",
    "- Qual é o valor de gasto médio por `jobArea`?\n",
    "- Qual é a PF que gastou menos (`totalSpent`)?\n",
    "- Quantos nomes e documentos repetidos existem nesse dataset?\n",
    "- Quantas linhas existem nesse dataset?\n",
    "\n",
    "### Particionamento de dados tratados com as regras descritas em `DATA QUALITY`\n",
    "\n",
    "- Particionar em arquivos PARQUET por estado (`state`)\n",
    "- Particionar em arquivos CSV por ano/mes/dia de nascimento (`birthDate`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
